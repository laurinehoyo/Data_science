---
title: "Update_project"
author: "Laurine_hoyo, 20306940"
date: "2023-11-19"
output: html_document
---
__1. INTRODUCTION__

_1.1 Overview and motivation_

OVERVIEW 
The origin of this project stems from the desire to purchase a second-hand moped by a member of our group. The idea was to use linear regression to easily find the best possible available offer for a used moped of a specific make and model, given its mileage and age. A model was then built to find the most undervalued moped for sale online.
We thought the same approach could be applied for valuing second-hand cars, and there would also be a lot more data available since they are more prevalent than motorcycles. We could also consider other relevant variables for a more in-depth comparison of prices and characteristics of the vehicles. Autoscout24.ch was found to be the perfect candidate for this because it is the largest online market for used cars in Switzerland, and the listings include a lot of additional information about the car that other websites do not, such as horsepower, fuel consumption, etc. 

MOTIVATION
The objective of this project is to make an easy to use tool that helps buyers find the best offers on the market for a specific make and model, given its characteristics. Autoscout24 does not display the estimated value of vehicles on the listings, and places paid listings at the top of the search results. Our model could potentially help buyers find the best deals on this marketplace more easily. We also aim to predict vehicle depreciation over time, and help buyers choose a car that retains more of its value by identifying the observable characteristics of these cars.
Another possible use for our models would be to help a dealership or car buying service such as webuyanycar.com set prices at which they can buy customers’ cars and stay profitable. We will also try to find a relationship between the car’s characteristics and the listing duration time, in order to determine which cars will sell the fastest. 


_1.2 Research Questions_

The main objective of our project is to identify and understand the physical factors that most influence used car prices. Specifically, we aim to determine how characteristics such as vehicle age, mileage, engine power and fuel consumption, as well as categorical characteristics such as fuel type, transmission and traction, affect the market value of used cars.
By understanding these relationships, we aim to provide valuable insights for used car buyers, enabling them to more accurately assess the fair value of vehicles on the market. Ultimately, the aim is to achieve a clearer, more quantitative understanding of what drives used car prices, which can help make the used car market more transparent and efficient for all concerned.

To achieve these objectives, our study is structured around three pivotal questions:

Which physical factors have the biggest impact on used car prices? 

What are the factors that influence the duration of a listing for a used car? 

How do different car features affect value depreciation over time? 




_1.2 Data_

Source : https://www.autoscout24.ch/fr

We obtained the five datasets corresponding to distinct car models from various brands and groups by extracting data from the used car market website Autoscout24.ch. The data extraction was carried out using the Chrome extension webscaper.io. Each table represents the total listings of used cars for a particular make and model at one given point in time. The data for the different tables were scraped between 07.10.2023 and 31.10.2023.



Description 

The datasets comprise five distinct car models originating from various brands. The models are the following : Audi A3, Skoda Octavia, Toyota Yaris, Volkswagen Golf, and Volvo XC60. While each table shares identical variables, the number of observations varies. Each observation represents a car sold on the website Autoscout24.ch.
Below are the variables that we kept : 
```{r}

```

Data clean-up

The cleaning process of our data was quite tedious. We used the same process for each of the five datasets, as they come from the same website and contain the same variables. 
The necessary libraries to clean our data were the packages “tidyverse”, and “lubridate”, which helped us format our dates. 
 
We started by only keeping the numbers in the columns price, kilometers, and listing.id by using the parse_number function. We do this because some observations may include characters such as “CHF”, “km/h”, and so on. 
 
We then took care of the column consumption and got rid of “l/100km” so as to only keep the number, and we set every “-“ to “NA”. When doing this, we saw that there were some outliers that should not have been in our dataset. Indeed, values jumped from 11.6 l/100km to 160 l/100km. This probably occurred when we scraped the data, there were probably some errors. Maybe the scraping software took another field’s value when the consumption field was blank. We then did the same process for the column power. We kept the unit of measurement horsepower instead of kW.
 
Now taking care of the column expertise, we changed the “oui/non” values to logical values TRUE/FALSE. We did the same for the accident and warranty columns.
 
We then fixed the column new.price by setting values “Oui/Non” to “NA”, because it was probably an error while scraping the data. We then parsed numbers from the remaining rows. While doing this, we saw in unique values some unrealistic new car prices, notably 1, 54, and 4309. We assumed these were errors and removed them. 
 
Afterwards, we dropped columns that contained meaningless information, and that are a result of scraping the data, such as webscraper.order, web.scraper.start.url, page and annonce.link. 
 
After this, we proceeded to use the package lubridate. We wanted to set the date column to class “Date” to simplify plotting. To do this we needed to format the values as YYYY.MM.DD, as they were originally at MM.YYYY. We looked at the data first and we removed the visible errors. We set the format to MM.YYYY, as the vector needs to be a character vector for the parse_date function to work, and we then parsed date. The final format is YYYY-MM-DD. 
We did the same for the expertise.date and created.date columns. 
 
We added a column to the datasets where values will be TRUE if the vehicle is potentially defective or in need of repairs, and FALSE if not. We removed these defective vehicles when creating our model because they could bias it, making it underestimate prices for functioning vehicles. We identified defective vehicles in two ways. The first way was using the accident column, which is TRUE if the seller has flagged the vehicle as having been in an accident in the past, and FALSE if not. The second way was to look for keywords in columns title, subtitle, and description.text which are common in listings with defective vehicles. We created a column where values are TRUE if one of the defective phrases is detected, and FALSE if not. If either of these two identifiers were TRUE, the vehicle would be deemed defective and not eligible to serve as data for creating our model.
 
We first created a vector of characters which are the defective keywords. We then created a second list where the keywords were likely to have negation before them, so as to not falsely flag vehicles as defective. We then created an "ok" keywords vector that overpowered the second defective keywords vector. We did the same for other languages that listings could be in, such as French, Italian, or English. We then created vectors for the keywords and added the column defective. 
We set to TRUE if any keyword from the vector is in the subtitle or description.text column, using the “for” function. We set to FALSE all the TRUE values that contain a keyword in the vector ok_keywords. We set to defective to TRUE where the column accident is TRUE. 
 
We set to NA if values are "-" in the fuel.type, transmission and drivetrain columns.
 
We created the columns vehicle.age and listing.age to be able to model without using dates. The unit of measurement is days.
 
We defined scraping_date which is the date of the most recently created listing, we assumed this corresponds to the scraping date since there are many listings posted each day for our data sets.


__2. EXPLORATORY DATA ANALYSIS__
```{r}

```

